---
title: "huizenzoeker_municipality.csv, huizenzoeker_province.csv, huizenzoeker_streets.csv"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: united
    toc: yes
    toc_float: yes
---

-----------------------------

#### Scraping Huizenzoeker.nl to Analyse the Dutch Housing Market: Which places in the Netherlands are hit hardest by the Dutch Housing Crisis, and which the least?

Currently, the housing crisis is one of the most prominent societal challenges in the Netherlands. The Dutch housing market is both very competitive as well as inaccessible as it must deal with a supply shortage, which in turn leads to long waiting lists for social housing. The transaction prices of houses are going through the roof, as CBS (Centraal Planbureau voor Statistiek, 2021) revealed that prices in the first quarter of 2021 were 11.3% higher compared to a year before, which is way above the average increase in Europe. Many prospective buyers have to overbid houses in order to ensure a place to live. A huge problem is that the amount of mortgage is determined by the appraisal value of the house, which causes many to put their own capital into the purchase. This makes it very challenging for new entrants on the market (think of first-time buyers, young professionals) to succeed in renting or buying a house or apartment, especially as many are still paying off large amounts of student debt. It appears that only 3% of first-time buyers are financially able to buy a home without getting themselves into serious financial trouble. The data sets that we created during this project allow us to answer questions regarding, for instance: 'Which places in the Netherlands are hit hardest by the Dutch Housing Crisis and which the least?'

We have considered a few multiple housing sites to incorporate into our project, where [Huizenzoeker.nl](https://www.huizenzoeker.nl/) appeared to be the most suitable option. This website offers a clear view of the Dutch housing market with a wide range of listings, displaying an extensive amount of information (per listing, province, municipality, residence, and even per street). While currently Funda.nl is the largest housing provider in the Netherlands, the site is not the most useful for this project. Funda as the large well-known source that it is, is strictly protecting its for data to brace the site against data capture by competitor sites. Similarly, Zoekallehuizen.nl offers a large range of listings too, but could not provide us with the interesting and important aspects of the housing crisis we were looking after, e.g. overbidding percentages. Moreover, we looked for housing sites for other countries, such as Remax.nl which is one of the largest housing websites and mainly focuses on housing in Spain and Belgium. However, the 'societal challenge' part of our research topic is what particularly interested us from the start, and therefore we decided to stick with analysing the Dutch Housing market. 

Our data source Huizenzoeker.nl fits well into the data aggregator and low scale/scope category of Figure W3.1: Data Source Exploration of the 'Fields of Gold' paper by Boegershausen et al. (2021). Namely, the data available on Huizenzoeker.nl is less detailed, but contains data from multiple platforms (multi-platform data), and it has only regional coverage as opposed to global coverage. In other words, it only presents data on the housing market for the municipalities in the Netherlands, thus for the most part it will only be useful to those living or planning to live in the Netherlands. Although Huizenzoeker.nl is lesser known (lesser users) than other housing sites (even those on regional level too) such as Funda, it offers the richer data and novel measures we need to answer our research questions. Instead of having to gather the data from numerous primary data providers in the housing sector, this data aggregator facilitated our collection of multi-platform data far more efficiently.

 \ 

<center>
<img width="400" src="https://www.peterwetzels.nl/templates/website-imz/img/general/logos/logo-huizenzoeker.png">
</center>  


 \ 

### Motivation 

-----------------------------

#### 1.1 For what purpose was the dataset created? 

As the seriousness of the housing crisis and the shortage of listings differs across the country, we aim to create multiple data sets with information on the current housing housing market for each province, municipality, and street of the Netherlands. These data sets will be helpful in identifying the places hit the hardest by the housing crisis, and which places seem relatively 'safe'. Thereby, we would like to facilitate first-time buyers and young professionals with this fundamental information in their search to buy or rent a house. Namely: 'Where may they find the best value for their money?' based on the percentage overbid statistics we provide for all provinces and municipalities. But that is not the only data these datasets include, we provide additional data compared to that what is offered by the broker! For example, we too provide insights into the price developments of the listings, which in turn may help consumers gain relevant information for purchase price-negotiations (and other direct information from the dutch 'Kadaster'). 

There are datasets about the Dutch housing market available already. However, these do not specifically focus on the overbidding aspect of the current crisis, which forms an essential part of our research. Besides that, in addition of narrowly focusing on certain areas of the Netherlands, we preferred to focus on all municipalities in the Netherlands to get a more complete picture of the current state of the housing crisis. By focusing on the municipalities, residences, and streets (but only for a subset, which will be explained in further detail later), the units we are analyzing are small enough to deeply dive into the housing market of the Netherlands locally (as opposed to only focusing on provinces). Yet, the units are large enough to maintain order and control in our data set (as opposed to focusing on every house that is for sale in the Netherlands).

 \ 

#### 1.2 Who created this dataset and on behalf of which entity?

This data set is created for the course [Online Data Collection and Management](https://odcm.hannesdatta.com) at Tilburg University, as part of the Master's program 'Marketing Analytics'. The contributors of the project are:

* [Lesley Haerkens](https://github.com/lesleyhaerkens), l.w.g.haerkens@tilburguniversity.edu

* [Mila Gargiulo](https://github.com/MilaGargiulo), m.r.e.m.gargiulo@tilburguniversity.edu

* [DaniÃ«lle van Bruggen](https://github.com/daniellevb00), d.m.vanbruggen@tilburguniversity.edu

The objective of the team project was to collect data via webscraping or an API, to complete the complete workflow for collecting web data. 
\ 


#### 1.3 Who funded the creation of the dataset? 

There was no funding granted for creation of the data set.

 \ 

### Composition

-----------------------------

#### 2.1 What do instances that comprise the dataset represent?

The instances that comprise the data set represent all __municipalities__ of the Netherlands, as being one type of instance. The entities summarize the data of the housing market (for every house) in that municipality. The values related to the municipalities in the Netherlands represent the averages per municipality. The instances are connected to each other by the province that they are in. Therefore, all municipalities  belong to a larger type of instance, the provinces. 
As a bonus to the data sets that were generated for each municipality and province, we created a scraper that navigates from province to municipality, from municipality to residence, and from residence to street names. Since this would generate an enormous amount of URLS, generating this data set for each street name in the Netherlands would take a lot of time (which is beyond the scope of this project). Therefore, to give an impression of how data on street-level looks like, we decided to focus on the province 'Noord-Brabant', the municipality 'Tilburg' and the residence 'Tilburg'. From the residence 'Tilburg' we extract all the streets (such as Warandelaan, the street name of Tilburg University!). 
Therefore, our scraper really generates multiple data sets; one for the provinces, one for the municipalities, and one for the streets of Tilburg, and all these can be considered as the instances that comprise the data set, only on different levels. For convenience, and since it is our main objective at the moment, we focus on the municipalities within this documentation. However, keep in mind that the same counts for all other levels. 

 \ 

#### 2.2 How many instances are there in total (of each type, if appropriate?)

If every municipality is seen as an instance, we would say there are 352 municipalities in total, which are spread over the 12 provinces of the Netherlands. 
 
```{r, echo=FALSE}
knitr::opts_chunk$set(error=TRUE)
```
 
```{r, message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
```
 
 
```{r, echo = FALSE, message=FALSE, warning=FALSE} 
huizenzoeker1 <- read_csv("../data/huizenzoeker_municipality.csv")
huizenzoeker1%>%count(provincie)
```
 
 

 \ 

#### 2.3 Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set? 

All municipalities in the Netherlands are included in our data set (the full population). However, since the data is grouped and displayed as an average for each municipality, our data set could be interpreted as a sample. Moreover, we created a subset of the streets for the residence Tilburg, as an illustration of the possibilities of scraping data both on province level and on street level. Generally speaking, as every listing is located in a municipality, the sample is certainly representative of the larger set. 

 \ 

#### 2.4 What data does each instance consist of?

To clarify, each province knows its own page and is at the same time the parent of several municipality pages (as described in question 2.2). However, the structure of this province and municipality page are almost identical. For this question, illustration is based on one of the municipality pages, Tilburg (Noord-Brabant). For this question, several *screenshots* were taken from the Huizenzoeker.nl site.

First, all pages display a map of the Netherlands and their specific location on the map. Next, all contain a link to all the houses that are for sale followed by a link for all houses that are for rent. Next, each page displays 4 'trend' statistics. Each of the 4 numbers contains a related number, reflecting the percentage difference of the statistic compared to the month before. The first trend refers to the average selling price of a house within the municipality/province. The second trend refers to the number of houses sold in the past month. The third trend refelcts the average selling price per squared meter. And the fourth trend indicates what the average outbidding percentage is within the municipality/province in question. These trends will be of high importance during our project.

<center>
<img width="400" alt="Screenshot 2021-10-12 at 12 27 31" src="https://user-images.githubusercontent.com/90346612/136939330-9f742c7a-599a-4292-93e6-ec4dd43d66ab.png">
</center>

 \ 

Additionally, all pages cover histograms that show price and housing supply trends.Next, a section is shown in which several questions are answered in unprocessed text. The first questions cover the exact same as the first 4 trend statistics. However, the last ones cover the population number and population growth/decline compared to the year before. This population-related information, again, will be of high relevance later in our project. 

<center>
<img width="400" alt="Screenshot 2021-10-12 at 12 36 56" src="https://user-images.githubusercontent.com/90346612/136940621-9fc2e4d0-7f6c-4afb-a07e-96fd890118fc.png">
</center>

 \ 

Furthermore, a pie chart showing the average age distribution in the province/municipality is included. Moreover, a statistic on average disposable income is included, which again will be important later in our project. Finally, at the bottom of the page random houses that are for sale/rent are displayed, followed by links that navigate to a 'child'-page (e.g. from province page to municipality page).

<center>
<img width="400" alt="Screenshot 2021-10-12 at 12 41 48" src="https://user-images.githubusercontent.com/90346612/136941544-e1f6e1c2-2aa7-4946-9457-d5534044846f.png">
</center>

 \ 

#### 2.5 Is there a label or target associated with each instance? 

From each province in the Netherlands, we intend to scrape all corresponding municipalities. For the provinces an associated URL is for example 'https://www.huizenzoeker.nl/woningmarkt/noord-brabant/', which changes to 'https://www.huizenzoeker.nl/woningmarkt/noord-brabant/tilburg/' for Tilburg. So, the instances that we want to scrape correspond to their own URLs. 

Moreover, within the code we wrote, we extracted the municipality or province name for each of these URLs, by scraping the title and removing the word 'Woningmarkt' from it. Therefore, we changed the official label to an artificial one for clarity purposes, e.g. now the municipality Tilburg can be identified through the label 'Tilburg', instead of its URL. This 'base' url (*i.e.*,  'https://www.huizenzoeker.nl/woningmarkt/noord-brabant/'), extends even further when navigating to residence and finally to street name. The url of 'Warandelaan', *e.g.*, is 'https://www.huizenzoeker.nl/woningmarkt/noord-brabant/tilburg/tilburg/warandelaan'.

 \ 

#### 2.6 Is any information missing from individual instances? 

Some data from Huizenzoeker.nl that we would have loved to scrape to extend our data set is displayed in charts and graphs, and for that reason, we are unable to grasp this data from the source code as it seemed more 'hidden' than the other information we scraped. Moreover, as the data is real-time data, there appear to be some missing values for some municipalities for certain variables. For example, in small municipalities or residences where not many people live, houses will not be sold as often as in larger municipalities, therefore it can appear that at the moment of scraping the data, for that municipality most of the variables contain NA values. As if there are no houses sold, there will also not an average asking price for this month, a % overbid or an average price per squared meter. 

\ 

#### 2.7 Are relationships between individual instances made explicit (e.g., user's movie ratings, social network links)? 

Yes, the municipalities are related to each other by the province that they are in. When running our code for all municipality URLs in a certain province, all information for every municipality within that province will be the output. The parent URL (province) and child URL (municipality) are __always__ connected. This also holds for residences and street names. This is explicitly visible in the URLs. For every municipality, the municipality name in the link follows the province name (see: question 2.5).

As is displayed here, in the municipalities data set we indicate for each municipality 'city' to which province it belongs, which links these individual municipalities to the provinces in the provinces data set. 
```{r, echo = FALSE, message=FALSE, warning=FALSE} 
head(huizenzoeker1)
```
But also for our bonus feature, the streets data set, each street is linked to the residence that it is in, which is too made explicit in the data set. 

```{r, echo = FALSE, message=FALSE, warning=FALSE} 
huizenzoeker2 <- read_csv("../data/huizenzoeker_streets.csv")
head(huizenzoeker2)
```


 \ 

#### 2.8 Are there recommended data splits (e.g. training,development/validation, testing)? 

There are no recommended data splits in our data set, since our data set is parsed and collected into one file. We chose to parse and collect the variables in our data set together in one script to make all the information quickly accessible. We think this is no problem mainly because of the following reason. Huizenzoeker.nl updates its content each month automatically. The structure and the URLs stay exactly the same, yet, the statistical numbers change per month. We designed our code in a way that it captures every number that is present at the moment, regardless of whether we run it, *e.g.*, in September versus October.

 \ 

#### 2.9 Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g. websites, tweets, other datasets)? If it links to or relies on external resources: 
#### a) are there guarantees that they will exist and remain constant over time; 

Huizenzoeker.nl states that, for over 10 years, they have made every effort possible to ensure that this website functions properly and is kept permanently accessible for reputational reasons. Huizenzoeker.nl edits the information offered on its site with the greatest possible care and devotes the same care to the composition of the site. However, it legally cannot guarantee the correctness and completeness of the data shown as a result of imperfections that may occur. Moreover, Huizenzoeker is able to adapt the website where and whenever they please. No restrictions hold. This information has been retrieved from the [disclaimer](https://www.huizenzoeker.nl/over-ons/disclaimer/) section on the Huizenzoeker.nl website.

#### b) are there official arhival versions of the complete datasets (*i.e.* including the external resources as they existed at the time the dataset was created).

Possibly for own utilization. However, no official archival versions of the complete data sets are available to us as the public of Huizenzoeker.nl. Huizenzoeker.nl displays real-time monthly data, and not so much archival data for the data we scrape to answer our research objective (there is for instance data on the 'prijsontwikkelingen' over the last couple of years, which means data for the previous years must be available too). The data we scrape from the municipality pages is data that is updated every month, so when scraping this page you do not get direct access to the figures or averages for the previous months. 

#### c) are there any restrictions (e.g., licenses, fees) associated with any of the external resources that might apply to a future user? 

The external resources include JAAP.nl and Huislijn.nl, who in turn extract data from other sites such as Funda.nl. These sites are all available for free, thus, no restrictions are present in the form of licenses and fees for future users. There is a premium (under ['Abonnementen'](https://www.huizenzoeker.nl/woningmarkt-dashboard/)) part of Huizenzoeker.nl, for which you do need to pay to access it. For our project, the premium information was irrelevant. 

 \ 

#### 2.10 Does the dataset contain data that might be considered confidential (e.g. data that is protected by legal priviledge or by doctorpatient confidentiality, data that includes the content of individuals non-public communications)? 

No, the data is not confidential. Therefore users do not have any rights to remove listings from the Huizenzoeker site. Only if their house is no longer for sale/rent on JAAP.nl, their listing will be removed. However, information on the house itself such as its value, year of construction, property size, will remain available. This information is considered as public.

 \ 

#### 2.11 Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? 

No the data can in no way be perceived as offensive, insulting, or threatening. 

 \ 

#### 2.12 Does the dataset relate to people? If not, you may skip the remaining questions in this section.

The dataset relates to people in the sense that data is available for variables such as the average disposable income and the age distribution in a certain municipality or residence.

 \ 

#### 2.13 Does the dataset identify any subpopulations (e.g., by age, gender)? If so, please describe how these subpopulations are identified and provide a description of their respective distributions within the dataset. 

Our dataset does not relate to sub populations, as we scrape houses and not people, so there is no need to identify sub populations.

 \ 

#### 2.14 Is it possible to identify individuals (*i.e.*, one or more natural persons), either directly or indirectly (*i.e.*, in combination with other data) from the dataset? 

This question is not applicable to our data set. 

 \ 

#### 2.15 Does the dataset contain data that might be considered sensitive in any way (e.g. data that reveals racial or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic data; forms of government identification, such as social security numbers; criminal history)?

This question is not applicable to our data set. 

 \ 

### Collection process 

-----------------------------

#### 3.1 How was the data associated with each instance acquired? Was the data directly observable (e.g., raw text, movie ratings), reported by subjects (e.g., survey responses), or indirectly inferred/derived from other data (e.g., part-of-speech tags, model-based guesses for age or language)? If data was reported by subjects or indirectly inferred/derived from other data, was the data validated/verified?

Via the selenium package we accessed ChromeDriverManager. Using this webdriver we scraped all the possible municipality URLs for the entire Huizenzoeker website. 

The next step was to extract all the variables described in question 2.8. One code has been created for this step. At the beginning of this code, we made sure all the output got saved into a json file. Next, one big for-loop is created that will loop through all of the municipality pages, making sure the code gets 5 seconds of sleep. Within the loop we loaded the BeautifulSoup package. We then defined the first variable intended identification purposes: the municipality name. These were all the steps that needed to be completed in order to scrape all the variables we wanted from the municipality pages. These variables have been created using multiple 'if' - 'else' statements, tailoring each variable to its corresponding html output that can be accessed when inspecting the municipality webpage. Furthermore, irrelevant characters/words have been dropped to enhance clarity. At the bottom of the code all the variables are appended into a list.

Using the 'pandas' package we were able to convert this list with variables into a large table (dataframe) containing all variables per municipality. This data frame, in turn, is converted into a csv file. All the data we scraped from the Huizenzoeker platform was data that was directly observable in the form of raw text.

 \ 

#### 3.2 What mechanisms or procedures were used to collect the data (e.g., hardware apparatus or sensor, manual human curation, software program, software API)? How were these mechanisms or procedures validated?

We scraped the data using Python's programming software in Jupyter Notebooks. By loading the packages BeautifulSoup, Selenium, requests, re, pandas, time, webdriver manager, and json, we were able to use functions allowing for our specific webscraping steps.

Huizenzoeker.nl does not provide an official software API (anymore), so we scraped the data by writing code ourselves.

 \ 

#### 3.3 If the dataset is a sample from a larger set, what was the sampling strategy (e.g., deterministic, probabilistic with specific sampling probabilities)?

Technically, we have taken the entire population, and no sample, to conduct our project with. We took all the municipality pages as input, an not a portion of them.

Yet, logically, we have taken a sample. Namely, a single unit would represent a single house in logical terms. However, as the statistics we were after were only available on an average-level on the municipality pages, we took the municipality pages as single units. A municipality page consists of average numbers from all the single houses present in that region. Thus, that is the sampling strategy applied. 

 \ 

#### 3.4 Who was involved in the data collection process (e.g., students, crowdworkers, contractors) and how were they compensated (e.g., how much were crowdworkers paid)?

In the data collection process the team members of this project were involved. In addition,  [Hannes Datta](https://github.com/hannesdatta), professor at Tilburg University and program creator of the [Online Data Collection and Management course](https://odcm.hannesdatta.com/) was involved in the data collection process in the form of guidance and supervision.

 \ 

#### 3.5 Over what timeframe was the data collected? Does this timeframe match the creation timeframe of the data associated with the instances (e.g., recent crawl of old news articles)? 

Huizenzoeker collects real-time data of the housing market. Namely, at the moment of writing the documentation Huizenzoeker.nl covers the data for September 2021 which is the most recent housing market data available. This too is the 



Huizenzoeker.nl covers the housing market data of September 2021. This is the most recent housing market data. Huizenzoeker.nl shows this most-recent data because the housing market changes every month (e.g., houses are sold, new houses are offered, the asking price may be more extremely outbid in one month than in the other month, etc.).

 \ 

#### 3.6 Were any ethical review processes conducted (e.g., by an institutional review board)?

This question is not applicable to our data set. 

 \ 

#### 3.7 Does the dataset relate to people? If not, you may skip the remaining questions in this section.

This question is not applicable to our data set. 

 \ 

#### 3.8 Did you collect the data from the individuals in question directly, or obtain it via third parties or other sources (e.g., websites)?

This question is not applicable to our data set. 

 \ 

#### 3.9 Were the individuals in question notified about the data collection? 

This question is not applicable to our data set. 

 \ 

#### 3.10 Did the individuals in question consent to the collection and use of their data? 

This question is not applicable to our data set. 

 \ 

#### 3.11 If consent was obtained, were the consenting individuals provided with a mechanism to revoke their consent in the future or for certain uses? If so, please provide a description, as well as a link or other access point to the mechanism (if appropriate).

This question is not applicable to our data set. 

 \ 

#### 3.12 Has an analysis of the potential impact of the dataset and its use on data subjects (e.g., a data protection impact analysis) been conducted?

This question is not applicable to our data set.  

 \ 


### Preprocessing, cleaning, labeling 

-----------------------------

#### 4.1 Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)?  

First of all, all the values of the variables have been cleaned in a way that they only give a certain numeric value or percentage as output (no additional words, and only consistent punctuation). This means removing the HTML tag words, stripping out unnecessary characters and retaining relevant substrings only. To achieve this, we made use of regular expressions (regex) to pre-process the textual data. When no numeric value exists for a specific municipality, we encoded that 'NA' will result as output for the variable in question. Furthermore, all the variables have been assigned a clear label, such that the numeric values are given a meaning. For example, we identified values as provinces, municipalities, streets, etc. Additionally, all the variables have been displayed in a table against all the municipalities/provinces as a small start in preprocessing. 

In addition, we use pagination to be able to scrape data on street-level. Interaction (*i.e.*, in the form of clicking buttons) is required since the large amount of streets for each residence is displayed on several page numbers. 

 \ 

#### 4.2 Was the ârawâ data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)? 

Yes, the raw output is being saved in a json file automatically, as part of our coding script. The json file can be accessed by running our Scraping Woningmarkt (Final Code) jupyter script. In addition, we stored our dataset locally, being able to monitor the process of our data collection process more easily (Boegershausen et al., 2021). Our data is stored in files rather than databases. The data set is structured (*i.e.*, it is downloaded as a clean pandas Dataframe) and the code can be run on one computer (*i.e.*, the size of our data set is not exhaustive).

 \ 
 

#### 4.3 Is the software used to preprocess/clean/label the instances available? 

We decided to use self-developed code that interfaces with high-level scraping libraries (e.g. Selenium and BeautifulSoup), as a software tool for data extraction. We did not choose to use a ready-made scraping toolkit like Monzenda, or packages that only require some coding like Scrapy for Python, as for the complexity of our data collection the self-developed code method seemed the most desirable. Developing the code ourselves in Python required quite some time and effort, however in the end it is a better way to actively manage the data quality and reproductibility than through the other methods. 

After pre-processing, cleaning, and labeling the data in Python, we exported the dataset to RStudio where we transformed the data set into one ready for analysis. Python and Rstudio, and the libraries Selenium and BeautifulSoup are all publicly available. So, together with our code, you can replicate our scraping efforts easily.

 \ 


### Uses

-----------------------------

#### 5.1 Has the dataset been used for any tasks already? 
The dataset has not been used for scientific research yet. However, to illustrate how one could use our dataset we provide several engaging figures.

##### In which provice of the Netherlands are houses currently most outbid?

```{r, echo=FALSE}
knitr::opts_chunk$set(error=TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(maps)
library(viridis)
library(tibble) 
library(sp)
library(extrafont)
library(readr)
library(tidyr)
library(tinytex)
library(dplyr)
huizenzoeker <- read_csv("../data/huizenzoeker_province.csv")
```



```{r, include=FALSE}
NL <- map_data("world", region = "Netherlands")
ggplot(NL, aes(x = long, y = lat)) +
  geom_polygon(aes( group = group, fill = region))+
  theme(legend.position = "none")

NLD <- readRDS("../src/reporting/gadm36_NLD_2_sp.rds")
NLD_data <- NLD@data
plot(NLD)

ggplot(data = NLD, aes(x = long, y = lat))+
  geom_polygon( ) +
  coord_fixed()
ggplot()+
  geom_polygon(data = NLD, aes(x = long, y = lat, group = group)) +
  coord_map()

NLD_fixed <- subset(NLD, !NLD$NAME_1  %in% c("Veldhoven"))
NLD_f<- fortify(NLD)

names_and_numbers <- data_frame(id=rownames(NLD_data),
                                Province=NLD_data$NAME_1) %>% 
  left_join(huizenzoeker, by = "Province")

final_map <- left_join(NLD_f, names_and_numbers, by = "id") 
```


```{r, message=FALSE, warning=FALSE, fig.align='center'}

ggplot(final_map) +
  theme_minimal() +
  geom_polygon(aes(x = long, y = lat, group = group, fill= perc_overboden)) +
  labs(x="", y="", title="Percentage van de vraagprijs overboden") +
  theme(plot.title = element_text(hjust = 0.5,size=15),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        legend.position = "bottom") +
  coord_map()+
  scale_fill_distiller(name = "% overboden", 
                       palette = "Reds",
                       direction = 1) +
  theme(legend.position = "right",
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank()) 

```

 \ 

#### 5.2 Is there a repository that links to any or all papers or systems that use the dataset? If so, please provide a link or other access point.

There are not many (if any) papers or systems that use this data set, so there is not really such repository that we can mention here. The following are some repositories on Github of projects that were the closest to our own: 

 * A simple python wrapper for the Huizenzoeker API (but last updated in oct 2013) = https://github.com/bpeschier/huizenzoeker
 
 * Using the Jaap API to look for rentals in Rotterdam = https://github.com/thomasvt1/HuizenZoeker

Which only emphasizes the need and potential for such a scraper and the added value it may have, as there currently is not an data set  publicly available alike ours...
 \ 

#### 5.3 What (other) tasks could the dataset be used for?

Broadly speaking, a suitable task this data set can be used for is helping (future) inhabitants of the Netherlands find their ideal home. By accessing our data, a person could find the best municipality to live in for this person's specific circumstances (e.g. specific disposable income level), find a region where the value-for-money seems to be of high standard, to help them in negotiations on the price, to help them find out what is the norm in terms of overbidding for each municipality, and more.

 \ 

#### 5.4 Is there anything about the composition of the data set or the way it was collected and preprocessed/cleaned/labeled that might impact future uses?

The only harms that could be done in the case of Huizenzoeker relates to financial harms, e.g. when one is misinformed about housing prices due to our data set. 

However, as long as Huizenzoeker does not incur drastic changes, no undesirable harms will arise. *also when there would be drastic changes on Huizenzoeker.nl then our code likely won't work anymore so in that case our scraper won't result in undesirable harms either, but just won't work) 

Future users of the data set could decide to implement more variables, or kick certain variables out. As long as this is done following the same steps as in our coding script, no harm can be done. 

 \ 

#### 5.5 Are there tasks for which the dataset should not be used? If so, please provide a description.

The data set can be used for any matters regarding the housing market in the Netherlands, at municipality-, province-, as well as street-level. For anything outside of this topic, the data set has no use.

 \